{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e1a5a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deer_images/train\n",
      "Directory exists\n",
      "deer_images/train/002d813bf4_jpg.rf.cc47c08da6d1bca885ae1b020924b630.jpg\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '002d813bf4_jpg.rf.cc47c08da6d1bca885ae1b020924b630.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 170\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 170\u001b[0m train \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/\u001b[39m\u001b[38;5;124m\"\u001b[39m)    \n\u001b[0;32m    171\u001b[0m test \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    172\u001b[0m validate \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[43], line 60\u001b[0m, in \u001b[0;36mload\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     58\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset_directory\u001b[38;5;241m+\u001b[39mdirectory\u001b[38;5;241m+\u001b[39mfile \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp: \n\u001b[0;32m     61\u001b[0m     line \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mreadlines()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m line[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '002d813bf4_jpg.rf.cc47c08da6d1bca885ae1b020924b630.txt'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from random import seed\n",
    "from random import random\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "\n",
    "def residual_block_generator():\n",
    "  model=tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(64,3,strides=(1,1),padding='same'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.LeakyReLU(),\n",
    "  tf.keras.layers.Conv2D(64,3,strides=(1,1),padding='same'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.LeakyReLU(),\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "def generator_model():\n",
    "  # k9n64s1\n",
    "  input = tf.keras.layers.Input(shape=(None,None,3))\n",
    "  input_conv_layer = tf.keras.layers.Conv2D(64,9,padding='same')(input)\n",
    "  input_conv_layer = tf.keras.layers.LeakyReLU()(input_conv_layer)\n",
    "  output_layer_1 = input_conv_layer\n",
    "\n",
    "  # Five Residual Blocks k3n64s1\n",
    "  for x in range(5):\n",
    "    residual_output = residual_block_generator()(output_layer_1)\n",
    "    # Elementwise Sum\n",
    "    output_layer_1 = tf.keras.layers.Add()([output_layer_1,residual_output])\n",
    "\n",
    "  # k3n64s1\n",
    "  output_layer_1 = tf.keras.layers.Conv2D(64,9,padding='same')(output_layer_1)\n",
    "  output_layer_1 = tf.keras.layers.BatchNormalization()(output_layer_1)\n",
    "  # Elementwise Sum\n",
    "  output_layer_1 = tf.keras.layers.Add()([output_layer_1,input_conv_layer])\n",
    "\n",
    "  # Upsample Block 1 k3n256s1\n",
    "  upsample_layer_1 = tf.keras.layers.Conv2D(256,3, strides=(1,1),padding='same')(output_layer_1)\n",
    "  upsample_layer_1 = tf.nn.depth_to_space(upsample_layer_1, 2)\n",
    "  upsample_layer_1 = tf.keras.layers.LeakyReLU()(upsample_layer_1)\n",
    "\n",
    "  # Upsample Block 2 k3n256s1\n",
    "  upsample_layer_2 = tf.keras.layers.Conv2D(256,3, strides=(1,1),padding='same')(upsample_layer_1)\n",
    "  upsample_layer_2 = tf.nn.depth_to_space(upsample_layer_2, 2)\n",
    "  upsample_layer_2 = tf.keras.layers.LeakyReLU()(upsample_layer_2)\n",
    "\n",
    "  # Output layer k9n3s1\n",
    "  output_layer_2 = tf.keras.layers.Conv2D(3,9,activation='tanh',padding='same')(upsample_layer_2)\n",
    "  generator = tf.keras.models.Model(input, output_layer_2)\n",
    "\n",
    "  #generator.summary()\n",
    "  return generator\n",
    "\n",
    "def discriminator_model():\n",
    "  # k3n64s1\n",
    "  input = tf.keras.layers.Input(shape=(128,128,3))\n",
    "  input_conv_layer = tf.keras.layers.Conv2D(64,3,padding='same')(input)\n",
    "  input_conv_layer = tf.keras.layers.LeakyReLU()(input_conv_layer)\n",
    "\n",
    "  # Residual Layer 1 k3n64s2\n",
    "  residual_layer_1 = tf.keras.layers.Conv2D(64,3,strides=(2,2),padding='same')(input_conv_layer)\n",
    "  residual_layer_1 = tf.keras.layers.BatchNormalization()(residual_layer_1)\n",
    "  residual_layer_1 = tf.keras.layers.LeakyReLU()(residual_layer_1)\n",
    "\n",
    "  # Residual Layer 2 k3n128s1\n",
    "  residual_layer_2 = tf.keras.layers.Conv2D(128,3,strides=(1,1),padding='same')(residual_layer_1)\n",
    "  residual_layer_2 = tf.keras.layers.BatchNormalization()(residual_layer_2)\n",
    "  residual_layer_2 = tf.keras.layers.LeakyReLU()(residual_layer_2)\n",
    "\n",
    "  # Residual Layer 3 k3n128s2\n",
    "  residual_layer_3 = tf.keras.layers.Conv2D(128,3,strides=(2,2),padding='same')(residual_layer_2)\n",
    "  residual_layer_3 = tf.keras.layers.BatchNormalization()(residual_layer_3)\n",
    "  residual_layer_3 = tf.keras.layers.LeakyReLU()(residual_layer_3)\n",
    "\n",
    "  # Residual Layer 4 k3n256s1\n",
    "  residual_layer_4 = tf.keras.layers.Conv2D(256,3,strides=(1,1),padding='same')(residual_layer_3)\n",
    "  residual_layer_4 = tf.keras.layers.BatchNormalization()(residual_layer_4)\n",
    "  residual_layer_4 = tf.keras.layers.LeakyReLU()(residual_layer_4)\n",
    "\n",
    "  # Residual Layer 5 k3n256s2\n",
    "  residual_layer_5 = tf.keras.layers.Conv2D(256,3,strides=(2,2),padding='same')(residual_layer_4)\n",
    "  residual_layer_5 = tf.keras.layers.BatchNormalization()(residual_layer_5)\n",
    "  residual_layer_5 = tf.keras.layers.LeakyReLU()(residual_layer_5)\n",
    "\n",
    "  # Residual Layer 6 k3n512s1\n",
    "  residual_layer_6 = tf.keras.layers.Conv2D(512,3,strides=(1,1),padding='same')(residual_layer_5)\n",
    "  residual_layer_6 = tf.keras.layers.BatchNormalization()(residual_layer_6)\n",
    "  residual_layer_6 = tf.keras.layers.LeakyReLU()(residual_layer_6)\n",
    "\n",
    "  # Residual Layer 7 k3n512s2\n",
    "  residual_layer_7 = tf.keras.layers.Conv2D(512,3,strides=(2,2),padding='same')(residual_layer_6)\n",
    "  residual_layer_7 = tf.keras.layers.BatchNormalization()(residual_layer_7)\n",
    "  residual_layer_7 = tf.keras.layers.LeakyReLU()(residual_layer_7)\n",
    "\n",
    "  output_layer = tf.keras.layers.Flatten()(residual_layer_7)\n",
    "  output_layer = tf.keras.layers.Dense(1024)(output_layer)\n",
    "  output_layer = tf.keras.layers.LeakyReLU()(output_layer)\n",
    "  output_layer = tf.keras.layers.Dense(1,activation='sigmoid')(output_layer)\n",
    "  discriminator = tf.keras.models.Model(input,output_layer)\n",
    "\n",
    "  #discriminator.summary()\n",
    "  return discriminator\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def build_data(data_image, data_label):\n",
    "  print(data_image, data_label)\n",
    "  image = tf.image.resize(data_image, [128,128])\n",
    "  image = tf.divide(image, 255)\n",
    "  print(image)\n",
    "  #cropped=tf.dtypes.cast(tf.image.random_crop(data['image'] / 255,(128,128,3)),tf.float32)\n",
    "  lr=tf.image.resize(image,(32,32))\n",
    "  return (lr,image * 2 - 1)\n",
    "\n",
    "def train_step(data,adv_ratio=0.001):\n",
    "  gen_loss,disc_loss=0,0\n",
    "  low_resolution,high_resolution=data\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    super_resolution = generator(low_resolution, training=True)\n",
    "    gen_loss = tf.reduce_mean( (high_resolution - super_resolution) ** 2 )\n",
    "\n",
    "    real_output = discriminator(high_resolution, training=True)\n",
    "    fake_output = discriminator(super_resolution, training=True)\n",
    "    adv_loss_g = generator_loss(fake_output) * adv_ratio\n",
    "    gen_loss += adv_loss_g\n",
    "    disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "\n",
    "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "# get dataset that contains images of cats and dogs\n",
    "train_data, validation_data, test_data = tfds.load(\n",
    "    \"cats_vs_dogs\", \n",
    "    # Reserve 10% for validation (from 50% to 60%) and 10% for test (from 60% to 70%)\n",
    "    split=[\"train[:50%]\", \"train[50%:60%]\", \"train[60%:70%]\"],\n",
    "    as_supervised=True)\n",
    "\n",
    "ds_img_100_to_120 = train_data.skip(100).take(20)\n",
    "# display\n",
    "for i, (image, label) in enumerate(iterable = ds_img_100_to_120, start = 0): \n",
    "    ax = plt.subplot(5, 4, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(int(label))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "generator = generator_model()\n",
    "discriminator = discriminator_model()\n",
    "\n",
    "generator_optimizer=tf.keras.optimizers.Adam(0.001)\n",
    "discriminator_optimizer=tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "if latest is not None:\n",
    "  print(\"Loading model\" + latest)\n",
    "  generator.load(latest)\n",
    "  discriminator.load(latest)\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "\n",
    "\n",
    "noise = tf.random.normal([1, 128, 128, 3])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n",
    "\n",
    "for epoch in range(150):\n",
    "  train_dataset_mapped = train_data.map(build_data,num_parallel_calls=tf.data.AUTOTUNE).batch(16)\n",
    "  val_dataset_mapped = test_data.map(build_data,num_parallel_calls=tf.data.AUTOTUNE).batch(16)\n",
    "\n",
    "  for image_batch in tqdm(train_dataset_mapped, position=0, leave=True):\n",
    "    train_step(image_batch)\n",
    "  # Save the model every 5 epochs\n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "  predictions = generator(noise, training=False)\n",
    "  fig = plt.figure(figsize=(32, 32))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(32, 32, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0])\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()\n",
    "\n",
    "noise = tf.random.normal([1, 128, 128, 3])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4921ac89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d97eb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
